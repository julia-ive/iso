{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "import numpy as np\n",
    "from keras.datasets import mnist\n",
    "# use Matplotlib (don't ask)\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baby's first Autoencoder\n",
    "\n",
    "We'll start simple, with a single fully-connected neural layer as encoder and as decoder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Input, Dense\n",
    "from keras.models import Model\n",
    "\n",
    "# this is the size of our encoded representations\n",
    "encoding_dim = 32  # 32 floats -> compression of factor 24.5, assuming the input is 784 floats\n",
    "\n",
    "# this is our input placeholder\n",
    "input_img = Input(shape=(784,))\n",
    "# \"encoded\" is the encoded representation of the input\n",
    "encoded = Dense(encoding_dim, activation='relu')(input_img)\n",
    "# \"decoded\" is the lossy reconstruction of the input\n",
    "decoded = Dense(784, activation='sigmoid')(encoded)\n",
    "\n",
    "# this model maps an input to its reconstruction\n",
    "autoencoder = Model(input_img, decoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's also create a separate encoder model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this model maps an input to its encoded representation\n",
    "encoder = Model(input_img, encoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll also make a decoder model here too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a placeholder for an encoded (32-dimensional) input\n",
    "encoded_input = Input(shape=(encoding_dim,))\n",
    "# retrieve the last layer of the autoencoder model\n",
    "decoder_layer = autoencoder.layers[-1]\n",
    "# create the decoder model\n",
    "decoder = Model(encoded_input, decoder_layer(encoded_input))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's train our autoencoder to reconstruct MNIST digits.\n",
    "\n",
    "First, we'll configure our model to use a per-pixel binary crossentropy loss, and the Adadelta optimizer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder.compile(optimizer='adadelta', loss='binary_crossentropy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's prepare our input data. We're using MNIST digits, and we're discarding the labels (since we're only interested in encoding/decoding the input images)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://s3.amazonaws.com/img-datasets/mnist.npz\n",
      "11493376/11490434 [==============================] - 1s 0us/step\n"
     ]
    }
   ],
   "source": [
    "(x_train, _), (x_test, _) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll normalise all the values between 0 and 1, and we'll flatten the 28x28 images into vectors of size 784 (by concatenation of the rows.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 784)\n",
      "(10000, 784)\n"
     ]
    }
   ],
   "source": [
    "x_train = x_train.astype('float32') / 255.\n",
    "x_test = x_test.astype('float32') / 255.\n",
    "x_train = x_train.reshape((len(x_train), np.prod(x_train.shape[1:])))\n",
    "x_test = x_test.reshape((len(x_test), np.prod(x_test.shape[1:])))\n",
    "print (x_train.shape)\n",
    "print (x_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll train the autoencoder for 50 epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/50\n",
      "60000/60000 [==============================] - 3s 43us/step - loss: 0.3569 - val_loss: 0.2721\n",
      "Epoch 2/50\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.2666 - val_loss: 0.2584\n",
      "Epoch 3/50\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.2489 - val_loss: 0.2367\n",
      "Epoch 4/50\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.2271 - val_loss: 0.2159\n",
      "Epoch 5/50\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.2099 - val_loss: 0.2018\n",
      "Epoch 6/50\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.1978 - val_loss: 0.1913\n",
      "Epoch 7/50\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.1886 - val_loss: 0.1833\n",
      "Epoch 8/50\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.1815 - val_loss: 0.1771\n",
      "Epoch 9/50\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.1758 - val_loss: 0.1717\n",
      "Epoch 10/50\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.1709 - val_loss: 0.1671\n",
      "Epoch 11/50\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.1665 - val_loss: 0.1629\n",
      "Epoch 12/50\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.1625 - val_loss: 0.1591\n",
      "Epoch 13/50\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.1588 - val_loss: 0.1554\n",
      "Epoch 14/50\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.1553 - val_loss: 0.1522\n",
      "Epoch 15/50\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.1522 - val_loss: 0.1490\n",
      "Epoch 16/50\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.1492 - val_loss: 0.1462\n",
      "Epoch 17/50\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.1464 - val_loss: 0.1434\n",
      "Epoch 18/50\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.1437 - val_loss: 0.1411\n",
      "Epoch 19/50\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.1412 - val_loss: 0.1384\n",
      "Epoch 20/50\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.1389 - val_loss: 0.1361\n",
      "Epoch 21/50\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.1366 - val_loss: 0.1339\n",
      "Epoch 22/50\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.1345 - val_loss: 0.1319\n",
      "Epoch 23/50\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.1325 - val_loss: 0.1299\n",
      "Epoch 24/50\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.1307 - val_loss: 0.1280\n",
      "Epoch 25/50\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.1288 - val_loss: 0.1263\n",
      "Epoch 26/50\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.1271 - val_loss: 0.1246\n",
      "Epoch 27/50\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.1255 - val_loss: 0.1231\n",
      "Epoch 28/50\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.1239 - val_loss: 0.1215\n",
      "Epoch 29/50\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.1224 - val_loss: 0.1201\n",
      "Epoch 30/50\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 0.1210 - val_loss: 0.1187\n",
      "Epoch 31/50\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.1197 - val_loss: 0.1175\n",
      "Epoch 32/50\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.1185 - val_loss: 0.1162\n",
      "Epoch 33/50\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.1173 - val_loss: 0.1151\n",
      "Epoch 34/50\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.1162 - val_loss: 0.1140\n",
      "Epoch 35/50\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.1152 - val_loss: 0.1130\n",
      "Epoch 36/50\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.1142 - val_loss: 0.1121\n",
      "Epoch 37/50\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.1134 - val_loss: 0.1113\n",
      "Epoch 38/50\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.1125 - val_loss: 0.1105\n",
      "Epoch 39/50\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 0.1118 - val_loss: 0.1097\n",
      "Epoch 40/50\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 0.1111 - val_loss: 0.1091\n",
      "Epoch 41/50\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.1104 - val_loss: 0.1084\n",
      "Epoch 42/50\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.1098 - val_loss: 0.1079\n",
      "Epoch 43/50\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.1093 - val_loss: 0.1073\n",
      "Epoch 44/50\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 0.1087 - val_loss: 0.1068\n",
      "Epoch 45/50\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.1082 - val_loss: 0.1063\n",
      "Epoch 46/50\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 0.1078 - val_loss: 0.1059\n",
      "Epoch 47/50\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 0.1074 - val_loss: 0.1055\n",
      "Epoch 48/50\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 0.1070 - val_loss: 0.1051\n",
      "Epoch 49/50\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 0.1066 - val_loss: 0.1048\n",
      "Epoch 50/50\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 0.1063 - val_loss: 0.1044\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f1c1304ca90>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "autoencoder.fit(x_train, x_train,\n",
    "                epochs=50,\n",
    "                batch_size=256,\n",
    "                shuffle=True,\n",
    "                validation_data=(x_test, x_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After 50 epochs, the autoencoder seems to reach a stable train/test loss value of about 0.11. We can try to visualize the reconstructed inputs and the encoded representations. We will use Matplotlib."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode and decode some digits\n",
    "# note that we take them from the *test* set\n",
    "encoded_imgs = encoder.predict(x_test)\n",
    "decoded_imgs = decoder.predict(encoded_imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x288 with 20 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "n = 10  # how many digits we will display\n",
    "plt.figure(figsize=(20, 4))\n",
    "for i in range(n):\n",
    "    # display original\n",
    "    ax = plt.subplot(2, n, i + 1)\n",
    "    plt.imshow(x_test[i].reshape(28, 28))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "\n",
    "    # display reconstruction\n",
    "    ax = plt.subplot(2, n, i + 1 + n)\n",
    "    plt.imshow(decoded_imgs[i].reshape(28, 28))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding a Sparsity Constraint on encoded representations\n",
    "\n",
    "In the previous example, the representations were only constrained by the size of the hidden layer (32). In such a situation, what typically happens is that the hidden layer is learning an approximation of PCA (principal component analysis). But another way to constrain the representations to be compact is to add a sparsity contraint on the activity of the hidden representations, so fewer units would \"fire\" at a given time. In Keras, this can be done by adding an `activity_regularizer` to our Dense layer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import regularizers\n",
    "\n",
    "encoding_dim = 32\n",
    "\n",
    "input_img = Input(shape=(784,))\n",
    "# add a Dense layer with a L1 activity regularizer\n",
    "encoded = Dense(encoding_dim, activation='relu',\n",
    "                activity_regularizer=regularizers.l1(10e-5))(input_img)\n",
    "decoded = Dense(784, activation='sigmoid')(encoded)\n",
    "\n",
    "# this model maps an input to its encoded representation\n",
    "autoencoder = Model(input_img, decoded)\n",
    "\n",
    "\n",
    "encoder = Model(input_img, encoded)\n",
    "encoded_input = Input(shape=(encoding_dim,))\n",
    "decoder_layer = autoencoder.layers[-1]\n",
    "decoder = Model(encoded_input, decoder_layer(encoded_input))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll train this model for 100 epochs with the regulariser included. This will make the model less prone to overfitting; it can also be trained for longer. We'll visualise the results while we're at it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "autoencoder.compile(optimizer='adadelta', loss='binary_crossentropy')\n",
    "autoencoder.fit(x_train, x_train,\n",
    "                epochs=100,\n",
    "                batch_size=256,\n",
    "                shuffle=True,\n",
    "                validation_data=(x_test, x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode and decode some digits\n",
    "# note that we take them from the *test* set\n",
    "encoded_imgs = encoder.predict(x_test)\n",
    "decoded_imgs = decoder.predict(encoded_imgs)\n",
    "n = 10  # how many digits we will display\n",
    "plt.figure(figsize=(20, 4))\n",
    "for i in range(n):\n",
    "    # display original\n",
    "    ax = plt.subplot(2, n, i + 1)\n",
    "    plt.imshow(x_test[i].reshape(28, 28))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "\n",
    "    # display reconstruction\n",
    "    ax = plt.subplot(2, n, i + 1 + n)\n",
    "    plt.imshow(decoded_imgs[i].reshape(28, 28))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It should look similar to the previous model, but the difference should be in the sparsity of the encoded representations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.19487739"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_imgs.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep Autoencoders\n",
    "\n",
    "We do not have to limit ourselves to a single layer as encoder or decoder, we could instead use a stack of layers, such as:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/100\n",
      "60000/60000 [==============================] - 2s 37us/step - loss: 0.3681 - val_loss: 0.2644\n",
      "Epoch 2/100\n",
      "60000/60000 [==============================] - 2s 30us/step - loss: 0.2595 - val_loss: 0.2561\n",
      "Epoch 3/100\n",
      "60000/60000 [==============================] - 2s 30us/step - loss: 0.2505 - val_loss: 0.2433\n",
      "Epoch 4/100\n",
      "60000/60000 [==============================] - 2s 29us/step - loss: 0.2331 - val_loss: 0.2238\n",
      "Epoch 5/100\n",
      "60000/60000 [==============================] - 2s 29us/step - loss: 0.2161 - val_loss: 0.2069\n",
      "Epoch 6/100\n",
      "60000/60000 [==============================] - 2s 30us/step - loss: 0.2015 - val_loss: 0.1934\n",
      "Epoch 7/100\n",
      "60000/60000 [==============================] - 2s 30us/step - loss: 0.1884 - val_loss: 0.1828\n",
      "Epoch 8/100\n",
      "60000/60000 [==============================] - 2s 30us/step - loss: 0.1805 - val_loss: 0.1767\n",
      "Epoch 9/100\n",
      "60000/60000 [==============================] - 2s 29us/step - loss: 0.1752 - val_loss: 0.1716\n",
      "Epoch 10/100\n",
      "60000/60000 [==============================] - 2s 30us/step - loss: 0.1701 - val_loss: 0.1650\n",
      "Epoch 11/100\n",
      "60000/60000 [==============================] - 2s 30us/step - loss: 0.1650 - val_loss: 0.1614\n",
      "Epoch 12/100\n",
      "60000/60000 [==============================] - 2s 28us/step - loss: 0.1607 - val_loss: 0.1585\n",
      "Epoch 13/100\n",
      "60000/60000 [==============================] - 2s 29us/step - loss: 0.1569 - val_loss: 0.1517\n",
      "Epoch 14/100\n",
      "60000/60000 [==============================] - 2s 29us/step - loss: 0.1531 - val_loss: 0.1494\n",
      "Epoch 15/100\n",
      "60000/60000 [==============================] - 2s 30us/step - loss: 0.1499 - val_loss: 0.1490\n",
      "Epoch 16/100\n",
      "60000/60000 [==============================] - 2s 29us/step - loss: 0.1471 - val_loss: 0.1443\n",
      "Epoch 17/100\n",
      "60000/60000 [==============================] - 2s 29us/step - loss: 0.1447 - val_loss: 0.1410\n",
      "Epoch 18/100\n",
      "60000/60000 [==============================] - 2s 30us/step - loss: 0.1426 - val_loss: 0.1410\n",
      "Epoch 19/100\n",
      "60000/60000 [==============================] - 2s 31us/step - loss: 0.1407 - val_loss: 0.1391\n",
      "Epoch 20/100\n",
      "60000/60000 [==============================] - 2s 29us/step - loss: 0.1389 - val_loss: 0.1351\n",
      "Epoch 21/100\n",
      "60000/60000 [==============================] - 2s 30us/step - loss: 0.1369 - val_loss: 0.1345\n",
      "Epoch 22/100\n",
      "60000/60000 [==============================] - 2s 30us/step - loss: 0.1354 - val_loss: 0.1327\n",
      "Epoch 23/100\n",
      "60000/60000 [==============================] - 2s 29us/step - loss: 0.1336 - val_loss: 0.1323\n",
      "Epoch 24/100\n",
      "60000/60000 [==============================] - 2s 30us/step - loss: 0.1322 - val_loss: 0.1303\n",
      "Epoch 25/100\n",
      "60000/60000 [==============================] - 2s 30us/step - loss: 0.1308 - val_loss: 0.1300\n",
      "Epoch 26/100\n",
      "60000/60000 [==============================] - 2s 30us/step - loss: 0.1296 - val_loss: 0.1294\n",
      "Epoch 27/100\n",
      "60000/60000 [==============================] - 2s 29us/step - loss: 0.1286 - val_loss: 0.1259\n",
      "Epoch 28/100\n",
      "60000/60000 [==============================] - 2s 29us/step - loss: 0.1272 - val_loss: 0.1270\n",
      "Epoch 29/100\n",
      "60000/60000 [==============================] - 2s 30us/step - loss: 0.1262 - val_loss: 0.1246\n",
      "Epoch 30/100\n",
      "60000/60000 [==============================] - 2s 30us/step - loss: 0.1255 - val_loss: 0.1241\n",
      "Epoch 31/100\n",
      "60000/60000 [==============================] - 2s 29us/step - loss: 0.1245 - val_loss: 0.1235\n",
      "Epoch 32/100\n",
      "60000/60000 [==============================] - 2s 29us/step - loss: 0.1238 - val_loss: 0.1212\n",
      "Epoch 33/100\n",
      "60000/60000 [==============================] - 2s 30us/step - loss: 0.1230 - val_loss: 0.1227\n",
      "Epoch 34/100\n",
      "60000/60000 [==============================] - 2s 30us/step - loss: 0.1222 - val_loss: 0.1206\n",
      "Epoch 35/100\n",
      "60000/60000 [==============================] - 2s 30us/step - loss: 0.1216 - val_loss: 0.1192\n",
      "Epoch 36/100\n",
      "60000/60000 [==============================] - 2s 30us/step - loss: 0.1208 - val_loss: 0.1198\n",
      "Epoch 37/100\n",
      "60000/60000 [==============================] - 2s 30us/step - loss: 0.1200 - val_loss: 0.1174\n",
      "Epoch 38/100\n",
      "60000/60000 [==============================] - 2s 29us/step - loss: 0.1193 - val_loss: 0.1167\n",
      "Epoch 39/100\n",
      "60000/60000 [==============================] - 2s 31us/step - loss: 0.1185 - val_loss: 0.1172\n",
      "Epoch 40/100\n",
      "60000/60000 [==============================] - 2s 30us/step - loss: 0.1177 - val_loss: 0.1151\n",
      "Epoch 41/100\n",
      "60000/60000 [==============================] - 2s 30us/step - loss: 0.1170 - val_loss: 0.1158\n",
      "Epoch 42/100\n",
      "60000/60000 [==============================] - 2s 29us/step - loss: 0.1163 - val_loss: 0.1149\n",
      "Epoch 43/100\n",
      "60000/60000 [==============================] - 2s 30us/step - loss: 0.1157 - val_loss: 0.1138\n",
      "Epoch 44/100\n",
      "60000/60000 [==============================] - 2s 31us/step - loss: 0.1151 - val_loss: 0.1129\n",
      "Epoch 45/100\n",
      "60000/60000 [==============================] - 2s 29us/step - loss: 0.1144 - val_loss: 0.1127\n",
      "Epoch 46/100\n",
      "60000/60000 [==============================] - 2s 28us/step - loss: 0.1138 - val_loss: 0.1115\n",
      "Epoch 47/100\n",
      "60000/60000 [==============================] - 2s 30us/step - loss: 0.1133 - val_loss: 0.1102\n",
      "Epoch 48/100\n",
      "60000/60000 [==============================] - 2s 31us/step - loss: 0.1127 - val_loss: 0.1116\n",
      "Epoch 49/100\n",
      "60000/60000 [==============================] - 2s 30us/step - loss: 0.1122 - val_loss: 0.1108\n",
      "Epoch 50/100\n",
      "60000/60000 [==============================] - 2s 30us/step - loss: 0.1119 - val_loss: 0.1093\n",
      "Epoch 51/100\n",
      "60000/60000 [==============================] - 2s 29us/step - loss: 0.1113 - val_loss: 0.1106\n",
      "Epoch 52/100\n",
      "60000/60000 [==============================] - 2s 29us/step - loss: 0.1110 - val_loss: 0.1086\n",
      "Epoch 53/100\n",
      "60000/60000 [==============================] - 2s 30us/step - loss: 0.1105 - val_loss: 0.1083\n",
      "Epoch 54/100\n",
      "60000/60000 [==============================] - 2s 29us/step - loss: 0.1102 - val_loss: 0.1075\n",
      "Epoch 55/100\n",
      "60000/60000 [==============================] - 2s 29us/step - loss: 0.1097 - val_loss: 0.1102\n",
      "Epoch 56/100\n",
      "60000/60000 [==============================] - 2s 30us/step - loss: 0.1094 - val_loss: 0.1073\n",
      "Epoch 57/100\n",
      "60000/60000 [==============================] - 2s 29us/step - loss: 0.1090 - val_loss: 0.1076\n",
      "Epoch 58/100\n",
      "60000/60000 [==============================] - 2s 30us/step - loss: 0.1087 - val_loss: 0.1074\n",
      "Epoch 59/100\n",
      "60000/60000 [==============================] - 2s 29us/step - loss: 0.1083 - val_loss: 0.1066\n",
      "Epoch 60/100\n",
      "60000/60000 [==============================] - 2s 30us/step - loss: 0.1080 - val_loss: 0.1070\n",
      "Epoch 61/100\n",
      "60000/60000 [==============================] - 2s 30us/step - loss: 0.1076 - val_loss: 0.1088\n",
      "Epoch 62/100\n",
      "60000/60000 [==============================] - 2s 30us/step - loss: 0.1073 - val_loss: 0.1056\n",
      "Epoch 63/100\n",
      "60000/60000 [==============================] - 2s 30us/step - loss: 0.1070 - val_loss: 0.1044\n",
      "Epoch 64/100\n",
      "60000/60000 [==============================] - 2s 29us/step - loss: 0.1066 - val_loss: 0.1057\n",
      "Epoch 65/100\n",
      "60000/60000 [==============================] - 2s 30us/step - loss: 0.1063 - val_loss: 0.1070\n",
      "Epoch 66/100\n",
      "60000/60000 [==============================] - 2s 30us/step - loss: 0.1060 - val_loss: 0.1062\n",
      "Epoch 67/100\n",
      "60000/60000 [==============================] - 2s 29us/step - loss: 0.1057 - val_loss: 0.1050\n",
      "Epoch 68/100\n",
      "60000/60000 [==============================] - 2s 30us/step - loss: 0.1055 - val_loss: 0.1037\n",
      "Epoch 69/100\n",
      "60000/60000 [==============================] - 2s 30us/step - loss: 0.1052 - val_loss: 0.1037\n",
      "Epoch 70/100\n",
      "60000/60000 [==============================] - 2s 29us/step - loss: 0.1048 - val_loss: 0.1040\n",
      "Epoch 71/100\n",
      "60000/60000 [==============================] - 2s 30us/step - loss: 0.1045 - val_loss: 0.1021\n"
     ]
    }
   ],
   "source": [
    "input_img = Input(shape=(784,))\n",
    "encoded = Dense(128, activation='relu')(input_img)\n",
    "encoded = Dense(64, activation='relu')(encoded)\n",
    "encoded = Dense(32, activation='relu')(encoded)\n",
    "\n",
    "decoded = Dense(64, activation='relu')(encoded)\n",
    "decoded = Dense(128, activation='relu')(decoded)\n",
    "decoded = Dense(784, activation='sigmoid')(decoded)\n",
    "\n",
    "autoencoder = Model(input_img, decoded)\n",
    "autoencoder.compile(optimizer='adadelta', loss='binary_crossentropy')\n",
    "\n",
    "autoencoder.fit(x_train, x_train,\n",
    "                epochs=100,\n",
    "                batch_size=256,\n",
    "                shuffle=True,\n",
    "                validation_data=(x_test, x_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After 100 epochs, it reaches a train and test loss of ~0.097, a bit better than our previous models. Our reconstructed digits look a bit better too:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
