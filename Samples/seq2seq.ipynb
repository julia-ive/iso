{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# seq2seq\n",
    "\n",
    "This is an implementation of `seq2seq` using PyTorch. I figure this would be a good way of actually understanding on how to implement this kind of network. From what I know so far, it looks like a pretty hefty many-to-many RNN that is split into two parts, an encoder and a decoder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import unicode_literals, print_function, division\n",
    "from io import open\n",
    "import unicodedata\n",
    "import string\n",
    "import re\n",
    "import random\n",
    "import os\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this particular problem I'll be following the official PyTorch tutorial for 'seq2seq' which involves attempting to translate english into french. \n",
    "\n",
    "## Parsing the Dataset\n",
    "\n",
    "We'll need a dataset. We'll use [this one]( http://www.manythings.org/anki/). We'll start by loading this dataset and parsing it into a class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "SOS_token = 0\n",
    "EOS_token = 1\n",
    "\n",
    "class Lang:\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        self.word2index = {}\n",
    "        self.word2count = {}\n",
    "        self.index2word = {\n",
    "            0: \"SOS\",\n",
    "            1: \"EOS\"\n",
    "        }\n",
    "        self.n_words = len(self.index2word.keys())\n",
    "    \n",
    "    def addSentence(self, sentence):\n",
    "        for word in sentence.split(' '):\n",
    "            self.addWord(word)\n",
    "    \n",
    "    def addWord(self, word):\n",
    "        if word not in self.word2index:\n",
    "            self.word2index[word] = self.n_words\n",
    "            self.word2count[word] = 1\n",
    "            self.index2word[self.n_words] = word\n",
    "            self.n_words += 1\n",
    "        else:\n",
    "            self.word2count[word] += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the files are in unicode (since they may have accents); we'll need to turn them into ASCII. We can also use this opportunity to make everything lowercase, and trim punctuation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unicodeToAscii(s):\n",
    "    return ''.join(\n",
    "        c for c in unicodedata.normalize('NFD', s)\n",
    "        if unicodedata.category(c) != 'Mn'\n",
    "    )\n",
    "def norm(s):\n",
    "    s = unicodeToAscii(s.lower().strip())\n",
    "    s = re.sub(r\"([.!?])\", r\" \\1\", s)\n",
    "    s = re.sub(r\"[^a-zA-Z.!?]+\", r\" \", s)\n",
    "    return s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll need to read the datafile, and split them by lines, and split lines into pairs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readLangs(lang1, lang2, reverse=False):\n",
    "    print(\"Reading lines..\")\n",
    "    \n",
    "    # read the file and split into lines\n",
    "    directory = \"../Datasets/Tutorials/seq2seq\"\n",
    "    filename = lang1 + \"-\" + lang2 + \".txt\"\n",
    "    filepath = os.path.join(directory, filename)\n",
    "    lines = open(filepath, encoding='utf-8').\\\n",
    "        read().strip().split(\"\\n\")\n",
    "    \n",
    "    # split every line into pairs\n",
    "    # note that the language phrases are split by a tab.\n",
    "    pairs = [[norm(s) for s in l.split('\\t')] for l in lines]\n",
    "    \n",
    "    # reverse the pairs\n",
    "    if reverse:\n",
    "        pairs = [list(reversed(p)) for p in pairs]\n",
    "        input_lang = Lang(lang2)\n",
    "        output_lang = Lang(lang1)\n",
    "    else:\n",
    "        input_lang = Lang(lang1)\n",
    "        output_lang = Lang(lang2)\n",
    "    \n",
    "    return input_lang, output_lang, pairs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll want to trim the data into relatively short and simple sentences. Let the max length = 10 words, including punctuation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length = 10\n",
    "\n",
    "englishPrefixes = (\n",
    "    \"i am \", \"i m \",\n",
    "    \"he is\", \"he s \",\n",
    "    \"she is\", \"she s\",\n",
    "    \"you are\", \"you re \",\n",
    "    \"we are\", \"we re \",\n",
    "    \"they are\", \"they re \"\n",
    "    )\n",
    "\n",
    "def filterPair(p):\n",
    "    check1 = len(p[0].split(' ')) < max_length\n",
    "    check2 = len(p[1].split(' ')) < max_length\n",
    "    check3 = p[1].startswith(englishPrefixes)\n",
    "    return check1 and check2 and check3\n",
    "\n",
    "def filterPairs(pairs):\n",
    "    return [pair for pair in pairs if filterPair(pair)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The process for sanitising the data looks like:\n",
    "\n",
    "- Read the text file, split it into lines and pairs.\n",
    "- Normalise the text.\n",
    "- Make word lists from sentences in pairs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading lines..\n",
      "Read 135842 sentence pairs.\n",
      "Trimmed to 10853 sentence pairs.\n",
      "Counting words..\n",
      "Counted words:\n",
      "fra 4489\n",
      "eng 2925\n",
      "['nous sommes devouees .', 'we re dedicated .']\n"
     ]
    }
   ],
   "source": [
    "def prepare(lang1, lang2, reverse=False):\n",
    "    inputLang, outputLang, pairs = readLangs(lang1, lang2, reverse)\n",
    "    print(\"Read %s sentence pairs.\" % len(pairs))\n",
    "    \n",
    "    pairs = filterPairs(pairs)\n",
    "    print(\"Trimmed to %s sentence pairs.\" % len(pairs))\n",
    "    \n",
    "    print(\"Counting words..\")\n",
    "    \n",
    "    for pair in pairs:\n",
    "        inputLang.addSentence(pair[0])\n",
    "        outputLang.addSentence(pair[1])\n",
    "        \n",
    "    print(\"Counted words:\")\n",
    "    print(inputLang.name, inputLang.n_words)\n",
    "    print(outputLang.name, outputLang.n_words)\n",
    "    \n",
    "    return inputLang, outputLang, pairs\n",
    "\n",
    "inputLang, outputLang, pairs = prepare(\"eng\", \"fra\", True)\n",
    "print(random.choice(pairs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing the Training Data\n",
    "\n",
    "To train, we'll need to have input and target tensors based on the input data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def indexesFromSentence(lang, sentence):\n",
    "    return [lang.word2index[word] for word in sentence.split(' ')]\n",
    "\n",
    "def tensorFromSentence(lang, sentence):\n",
    "    indexes = indexesFromSentence(lang, sentence)\n",
    "    indexes.append(EOS_token)\n",
    "    return torch.tensor(indexes, dtype=torch.long, device=device).view(-1,1)\n",
    "\n",
    "def tensorsFromPair(pair):\n",
    "    inputTensor = tensorFromSentence(inputLang, pair[0])\n",
    "    targetTensor = tensorFromSentence(outputLang, pair[1])\n",
    "    return (inputTensor, targetTensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Seq2Seq Model\n",
    "\n",
    "In this particular example we'll be using GRUs (gated recurrent units).\n",
    "\n",
    "### Encoder\n",
    "\n",
    "This part is a RNN that otuputs some value for every word from the input sentence. For every input word the encoder outputs some vector, and a hidden state. This hidden state is the input for the next input word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, inputSize, hiddenSize):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.hiddenSize = hiddenSize\n",
    "        self.embedding = nn.Embedding(inputSize, hiddenSize)\n",
    "        self.gru = nn.GRU(hiddenSize, hiddenSize)\n",
    "    \n",
    "    def forward(self, input, hidden):\n",
    "        embedded = self.embedding(input).view(1,1,-1)\n",
    "        output = embedded\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "        return output, hidden\n",
    "    \n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1,1, self.hiddenSize, device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decoder\n",
    "\n",
    "In the tutorial they describe the decoder as using the last output of the encoder as $y_0$. This is represented as the **context vector**. At each step of the encoding, the decoder is given an input token and a hidden state. The initial input token is the start of the string `<SOS>` (which we described at the beginning), and there is also an `<EOS>` (the end of string)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, hiddenSize, outputSize):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.hiddenSize = hiddenSize\n",
    "        \n",
    "        self.embedding = nn.Embedding(outputSize, hiddenSize)\n",
    "        self.gru = nn.GRU(hiddenSize, hiddenSize)\n",
    "        self.out = nn.Linear(hiddenSize, outputSize)\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "    \n",
    "    def forward(self, input, hidden):\n",
    "        output = self.embedding(input).view(1,1,-1)\n",
    "        output = F.relu(output)\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "        output = self.softmax(self.out(output[0]))\n",
    "        return output, hidden\n",
    "    \n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1,1, self.hiddenSize, device=device)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Attention Decoder\n",
    " \n",
    "This is the attention mechanism which makes this network model different from the others. The Attention mechanism allows the decoder to *focus* on a different part of the encoders outputs for every step of the decoder's own inputs. Here's a TLDR:\n",
    "\n",
    "- Calculate a set of attention weights.\n",
    "- Dot product the attention weights with the encoder output vectors.\n",
    "- This result should contain information about that specific part of the input sequence, which helps the decoder choose the right words. We'll store this into a variable called `attentionApplied`.\n",
    "\n",
    "Calculating the attention weights is done with another feed-forward layer `attention`, using the decoder's inputs and hidden states as inputs. There's sentences of all sizes so we'll need to choose a maximum sentence length (i.e the input length for the decoder outputs) that it can apply to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttentionDecoder(nn.Module):\n",
    "    def __init__(self, hiddenSize, outputSize, dropout=0.1, maxLength = max_length):\n",
    "        super(AttentionDecoder, self).__init__()\n",
    "        self.hiddenSize = hiddenSize\n",
    "        self.outputSize = outputSize\n",
    "        self.dropoutProbability = dropout\n",
    "        self.maxLength = maxLength\n",
    "        \n",
    "        self.embedding = nn.Embedding(self.outputSize, self.hiddenSize)\n",
    "        self.attention = nn.Linear(self.hiddenSize * 2, self.maxLength)\n",
    "        self.attentionCombined = nn.Linear(self.hiddenSize * 2, self.hiddenSize)\n",
    "        self.dropout = nn.Dropout(self.dropoutProbability)\n",
    "        self.gru = nn.GRU(self.hiddenSize, self.hiddenSize)\n",
    "        self.out = nn.Linear(self.hiddenSize, self.outputSize)\n",
    "    \n",
    "    def forward(self, input, hidden, encoderOutputs):\n",
    "        embedded = self.embedding(input).view(1,1,-1)\n",
    "        embedded = self.dropout(embedded)\n",
    "        \n",
    "        attentionWeights = F.softmax(\n",
    "            self.attention(torch.cat((embedded[0], hidden[0]), 1)), dim=1)\n",
    "        attentionApplied = torch.bmm(attentionWeights.unsqueeze(0),\n",
    "                                    encoderOutputs.unsqueeze(0))\n",
    "        \n",
    "        output = torch.cat((embedded[0], attentionApplied[0]), 1)\n",
    "        output = self.attentionCombined(output).unsqueeze(0)\n",
    "        \n",
    "        output = F.relu(output)\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "        \n",
    "        output = F.log_softmax(self.out(output[0]), dim=1)\n",
    "        return output, hidden, attentionWeights\n",
    "\n",
    "    \n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1,1, self.hiddenSize, device=device)\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the Model\n",
    "\n",
    "We'll need to run the input sequence through the encoder, keep track of the outputs, and the latest hidden state. Then we'll feed the decoder the `<SOS>` token and the latest hidden state as it's first hidden state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "teacherForcingRatio = 0.5\n",
    "\n",
    "def train(tensorIn, tensorOut, encoder, decoder, encoderOptimiser, decoderOptimiser, criterion, maxLength = max_length):\n",
    "    encoderHidden = encoder.initHidden()\n",
    "    \n",
    "    encoderOptimiser.zero_grad()\n",
    "    decoderOptimiser.zero_grad()\n",
    "    \n",
    "    inputLength = tensorIn.size(0)\n",
    "    targetLength = tensorOut.size(0)\n",
    "    \n",
    "    loss = 0\n",
    "    \n",
    "    # set up encoder computation\n",
    "    encoderOutputs = torch.zeros(maxLength, encoder.hiddenSize, device=device)\n",
    "\n",
    "    for ei in range(inputLength):\n",
    "        encoderOutput, encoderHidden = encoder(tensorIn[ei], encoderHidden)\n",
    "        encoderOutputs[ei] = encoderOutput[0,0]\n",
    "    \n",
    "    # set up decoder variables\n",
    "    decoderInput = torch.tensor([[SOS_token]], device=device)\n",
    "    decoderHidden = encoderHidden\n",
    "    \n",
    "    enableTeacherForcing = False\n",
    "    if random.random() < teacherForcingRatio:\n",
    "        enableTeacherForcing = True\n",
    "    \n",
    "    if enableTeacherForcing:\n",
    "        # teacher forcing: feeds the target as the next input.\n",
    "        for di in range(targetLength):\n",
    "            # compute the output of each decoder state\n",
    "            decoderOutput, decoderHidden, decoderAttention = decoder(decoderInput, decoderHidden, encoderOutputs)\n",
    "            # calculate the loss\n",
    "            loss += criterion(decoderOutput, tensorOut[di])\n",
    "            # feed this output to the next input\n",
    "            decoderInput = tensorOut[di]\n",
    "    else:\n",
    "        # no techer forcing: use the predicted output as the next input.\n",
    "        for di in range(targetLength):\n",
    "            # compute the output of each decoder state\n",
    "            decoderOutput, decoderHidden, decoderAttention = decoder(decoderInput, decoderHidden, encoderOutputs)\n",
    "            toPV, toPI = decoderOutput.topk(1)\n",
    "            # detach from history as input\n",
    "            decoderInput = toPI.squeeze().detach()\n",
    "            # calculate the loss\n",
    "            loss += criterion(decoderOutput, tensorOut[di])\n",
    "            # if we found `<EOS>` at this iteration, then break.\n",
    "            if decoderInput.item() == EOS_token:\n",
    "                break\n",
    "    \n",
    "    loss.backward()\n",
    "    encoderOptimiser.step()\n",
    "    decoderOptimiser.step()\n",
    "    \n",
    "    return loss.item()/targetLength"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's a helper function to print the time elapsed and the estimated time remaining given the current time and progress:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import math\n",
    "\n",
    "\n",
    "def asMinutes(s):\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)\n",
    "\n",
    "\n",
    "def timeSince(since, percent):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    es = s / (percent)\n",
    "    rs = es - s\n",
    "    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The training process looks something like this:\n",
    "\n",
    "- Start a timer.\n",
    "- Initialise optimisers and criterion.\n",
    "- Create set of training pairs.\n",
    "- Start empty losses array for plotting.\n",
    "\n",
    "Then we'll call `train` many times and occasionally print the progress and average loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainIters(encoder, decoder, iterations, printEvery=1000, plotEvery=100, learningRate=0.01):\n",
    "    # store statistics so we can use them to \n",
    "    # show progress.\n",
    "    start = time.time()\n",
    "    plotLosses = []\n",
    "    printLossTotal = 0\n",
    "    plotLossTotal = 0\n",
    "    \n",
    "    # setup optimisers\n",
    "    encoderOptimiser = optim.SGD(encoder.parameters(), lr=learningRate)\n",
    "    decoderOptimiser = optim.SGD(decoder.parameters(), lr=learningRate)\n",
    "    trainingPairs = [tensorsFromPair(random.choice(pairs)) for i in range(iterations)]\n",
    "    criterion = nn.NLLLoss()\n",
    "    \n",
    "    for i in range(1, iterations + 1):\n",
    "        # set up variables needed for training.\n",
    "        trainingPair = trainingPairs[i-1]\n",
    "        tensorIn, tensorOut = trainingPair[0], trainingPair[1]\n",
    "        # calculate loss.\n",
    "        loss = train(tensorIn, tensorOut, encoder, decoder, encoderOptimiser, decoderOptimiser, criterion)\n",
    "        # increment our print and plot.\n",
    "        printLossTotal += loss\n",
    "        plotLossTotal += loss\n",
    "        \n",
    "        # print mechanism\n",
    "        if i % printEvery == 0:\n",
    "            printLossAvg = printLossTotal / printEvery\n",
    "            # reset the print loss.\n",
    "            printLossTotal = 0\n",
    "            print('%s (%d %d%%) %.4f' % (timeSince(start, i / iterations),\n",
    "                                         i, i / iterations * 100, printLossAvg))\n",
    "        # plot mechanism\n",
    "        if i % plotEvery == 0:\n",
    "            plotLossAvg = plotLossTotal / plotEvery\n",
    "            plotLosses.append(plotLossAvg)\n",
    "            plotLossTotal = 0\n",
    "    \n",
    "    showPlot(plotLosses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting Results\n",
    "\n",
    "Involves `matplotlib`, using the array of loss `plot_losses` saved while training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.switch_backend('agg')\n",
    "import matplotlib.ticker as ticker\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def showPlot(points):\n",
    "    plt.figure()\n",
    "    fig, ax = plt.subplots()\n",
    "    # this locator puts ticks at regular intervals\n",
    "    loc = ticker.MultipleLocator(base=0.2)\n",
    "    ax.yaxis.set_major_locator(loc)\n",
    "    plt.plot(points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation\n",
    "\n",
    "Looks like training, but there's no targets so we feed the decoder's predictions back to itself for each step. Every time it predicts a word, we add it to the output string, and if it predicts the EOS token we stop there. We also store the decoder's attention outputs for display later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(encoder, decoder, sentence, maxLength = max_length):\n",
    "    with torch.no_grad():\n",
    "        decodedWords = []\n",
    "        \n",
    "        # set up encoder\n",
    "        tensorIn = tensorFromSentence(input_lang, sentence)\n",
    "        inputLength = tensorIn.size()[0]\n",
    "        encoderHidden = encoder.initHidden()\n",
    "        encoderOutputs = torch.zeros(maxLength, encoder.hiddenSize, device=device)\n",
    "        \n",
    "        # add variables into our encoder.\n",
    "        for i in range(inputLength):\n",
    "            encoderOutput, encoderHidden = encoder(tensorIn[i], encoderHidden)\n",
    "            encoderOutputs[i] += encoderOutput[0,0]\n",
    "        \n",
    "        # set up decoder\n",
    "        decoderInput = torch.tensor([[SOS_token]], device=device)\n",
    "        decoderHidden = encoderHidden\n",
    "        decoderAttentions = torch.zeros(maxLength, maxLength)\n",
    "        \n",
    "        # iterate through the decoder states and retrieve\n",
    "        # the outputs.\n",
    "        for i in range(maxLength):\n",
    "            decoderOutput, decoderHidden, DecoderAttention = decoder(decoderInput, decoderHidden, encoderOutputs)\n",
    "            decoderAttentions[i] = decoderAttention.data\n",
    "            toPV, toPI, decoderOutput.data.topk(1)\n",
    "            \n",
    "            # if we found the end of string token then we're done.\n",
    "            if toPI.item() == EOS_token:\n",
    "                decoded_words.append('<EOS>')\n",
    "                break\n",
    "            else:\n",
    "                decodedWords.append(outputLang.index2word[toPI.item()])\n",
    "            \n",
    "            # format toPI to something the decoder can understand.\n",
    "            decoderInput = toPI.squeeze().detach()\n",
    "        \n",
    "        return decodedWords, decoderAttentions[:i + 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll also evaluate random sentences from the training set and print the input, target, and output to make some subjective QA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluateRandomly(encoder, decoder, n=10):\n",
    "    for i in range(n):\n",
    "        pair = random.choice(pairs)\n",
    "        print('>', pair[0])\n",
    "        print('=', pair[1])\n",
    "        output_words, attentions = evaluate(encoder, decoder, pair[0])\n",
    "        output_sentence = ' '.join(output_words)\n",
    "        print('<', output_sentence)\n",
    "        print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0m 30s (- 37m 41s) (1000 1%) 3.4950\n",
      "0m 55s (- 33m 57s) (2000 2%) 2.8802\n",
      "1m 21s (- 32m 32s) (3000 4%) 2.7956\n",
      "1m 47s (- 31m 42s) (4000 5%) 2.6586\n",
      "2m 12s (- 30m 59s) (5000 6%) 2.5549\n",
      "2m 38s (- 30m 22s) (6000 8%) 2.4764\n",
      "3m 3s (- 29m 46s) (7000 9%) 2.3788\n",
      "3m 29s (- 29m 15s) (8000 10%) 2.3384\n",
      "3m 55s (- 28m 48s) (9000 12%) 2.2574\n",
      "4m 21s (- 28m 21s) (10000 13%) 2.2011\n",
      "4m 47s (- 27m 53s) (11000 14%) 2.1309\n",
      "5m 13s (- 27m 25s) (12000 16%) 2.0874\n",
      "5m 39s (- 26m 59s) (13000 17%) 2.0774\n",
      "6m 5s (- 26m 32s) (14000 18%) 1.9705\n",
      "6m 31s (- 26m 6s) (15000 20%) 1.9591\n",
      "6m 57s (- 25m 39s) (16000 21%) 1.8418\n",
      "7m 23s (- 25m 12s) (17000 22%) 1.8677\n",
      "7m 49s (- 24m 47s) (18000 24%) 1.7987\n",
      "8m 15s (- 24m 21s) (19000 25%) 1.8160\n",
      "8m 42s (- 23m 56s) (20000 26%) 1.7091\n",
      "9m 8s (- 23m 29s) (21000 28%) 1.6856\n",
      "9m 34s (- 23m 4s) (22000 29%) 1.6646\n",
      "10m 0s (- 22m 38s) (23000 30%) 1.6507\n",
      "10m 27s (- 22m 12s) (24000 32%) 1.6445\n",
      "10m 53s (- 21m 46s) (25000 33%) 1.4921\n",
      "11m 19s (- 21m 21s) (26000 34%) 1.5132\n",
      "11m 46s (- 20m 55s) (27000 36%) 1.5091\n",
      "12m 12s (- 20m 29s) (28000 37%) 1.4410\n",
      "12m 38s (- 20m 3s) (29000 38%) 1.4431\n",
      "13m 4s (- 19m 36s) (30000 40%) 1.3864\n",
      "13m 30s (- 19m 9s) (31000 41%) 1.3683\n",
      "13m 56s (- 18m 43s) (32000 42%) 1.3655\n",
      "14m 21s (- 18m 16s) (33000 44%) 1.2728\n",
      "14m 48s (- 17m 50s) (34000 45%) 1.2842\n",
      "15m 14s (- 17m 25s) (35000 46%) 1.2465\n",
      "15m 40s (- 16m 59s) (36000 48%) 1.2530\n",
      "16m 7s (- 16m 33s) (37000 49%) 1.1857\n",
      "16m 33s (- 16m 7s) (38000 50%) 1.1870\n"
     ]
    }
   ],
   "source": [
    "## Training & Evaluating\n",
    "\n",
    "hiddenSize = 256\n",
    "modelEncoder = Encoder(inputLang.n_words, hiddenSize).to(device)\n",
    "modelAttentionDecoder = AttentionDecoder(hiddenSize, outputLang.n_words, dropout=0.1).to(device)\n",
    "trainIters(modelEncoder, modelAttentionDecoder, 75000, printEvery=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results\n",
    "\n",
    "Now that our seq2seq model has finished training, we can see how good it is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluateRandomly(encoder1, attn_decoder1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualising Attention\n",
    "\n",
    "We can interpret the attention outputs - it's quite useful since they're used to weight specific encoder outputs of the input sequence. With this, we can see where the network is most focused at each time step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_words, attentions = evaluate(\n",
    "    encoder1, attn_decoder1, \"je suis trop froid .\")\n",
    "plt.matshow(attentions.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def showAttention(input_sentence, output_words, attentions):\n",
    "    # Set up figure with colorbar\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111)\n",
    "    cax = ax.matshow(attentions.numpy(), cmap='bone')\n",
    "    fig.colorbar(cax)\n",
    "\n",
    "    # Set up axes\n",
    "    ax.set_xticklabels([''] + input_sentence.split(' ') +\n",
    "                       ['<EOS>'], rotation=90)\n",
    "    ax.set_yticklabels([''] + output_words)\n",
    "\n",
    "    # Show label at every tick\n",
    "    ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "    ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def evaluateAndShowAttention(input_sentence):\n",
    "    output_words, attentions = evaluate(\n",
    "        encoder1, attn_decoder1, input_sentence)\n",
    "    print('input =', input_sentence)\n",
    "    print('output =', ' '.join(output_words))\n",
    "    showAttention(input_sentence, output_words, attentions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluateAndShowAttention(\"elle a cinq ans de moins que moi .\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluateAndShowAttention(\"elle est trop petit .\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluateAndShowAttention(\"je ne crains pas de mourir .\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluateAndShowAttention(\"c est un jeune directeur plein de talent .\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
